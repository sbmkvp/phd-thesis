## Introduction

Data has been collected at a national level for a long period of time. The size
of the data is unique in terms of size and complexity. It is neither small
enough for desktop processing nor big enough for a cluster. We define this a
medium sized slow data. We develop a minimal, open-source, free toolkit for the
collection, storage, analysis and dissemination of the information. We start by
looking at the size and complexity of our data set. Make a list of requirements.
Choose tools for each requirement and finally integrate all the tools to put
together a complete took kit that suits our needs finally we do some test case
scenarios and evaluate performance of our toolkit.

## Literature on Big data

What is big data. The arguments critique. 
